@article{Abrarov2015,
abstract = {A new sampling methodology based on an incomplete cosine expansion series is presented as an alternative to the traditional sinc function approach. Numerical integration shows that this methodology is efficient and practical. Applying the incomplete cosine expansion we obtain a rational approximation of the complex error function that with the same number of the summation terms provides an accuracy exceeding the Weideman's approximation accuracy by several orders of the magnitude. Application of the expansion results in an integration consisting of elementary function terms only. Consequently, this approach can be advantageous for accurate and rapid computation.},
archivePrefix = {arXiv},
arxivId = {1407.0533},
author = {Abrarov, S. M. and Quine, B. M.},
doi = {10.1016/j.amc.2015.01.072},
eprint = {1407.0533},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Complex error function,Numerical integration,Rational approximation,Sampling,Sinc function,Voigt function},
month = {may},
pages = {425--435},
publisher = {Elsevier Inc.},
title = {{Sampling by incomplete cosine expansion of the sinc function: Application to the Voigt/complex error function}},
volume = {258},
year = {2015}
}
@article{abr15_1,
abstract = {We present a rational approximation for rapid and accurate computation of the Voigt function, obtained by sampling and residue calculus. The computational test reveals that with only {\$}16{\$} summation terms this approximation provides average accuracy {\$}{\{}10{\^{}}{\{} - 14{\}}{\}}{\$} over a wide domain of practical interest {\$}0 {\textless} x {\textless} 40,000{\$} and {\$}{\{}10{\^{}}{\{} - 4{\}}{\}} {\textless} y {\textless} {\{}10{\^{}}2{\}}{\$} for applications using the HITRAN molecular spectroscopic database. The proposed rational approximation takes less than half the computation time of that required by Weideman$\backslash$text{\{}'{\}}s rational approximation. Algorithmic stability is achieved due to absence of the poles at {\$}y \backslashgeqslant 0{\$} and {\$} - \backslashinfty {\textless} x {\textless} \backslashinfty {\$}.},
archivePrefix = {arXiv},
arxivId = {1504.00322},
author = {Abrarov, Sanjar M. and Quine, Brendan M.},
doi = {10.5539/jmr.v7n2p163},
eprint = {1504.00322},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/abr15pdf.pdf:pdf},
issn = {1916-9795},
journal = {Journal of Mathematics Research},
month = {jun},
number = {2},
pages = {163},
publisher = {Canadian Center of Science and Education},
title = {{A Rational Approximation for Efficient Computation of the Voigt Function in Quantitative Spectroscopy}},
volume = {7},
year = {2015}
}
@article{Albrecher2007,
abstract = {In this paper, the recent failure of the Canary Wharf project at London Docklands in the wake of the financial collapse of Canadian property giant, Olympia and York, is critically examined. Some theoretical pointers are offered as to how the Canary Wharf affair arose, the logic through which it was implemented, and the political and financial mechanisms deployed to ride the storm are highlighted. The shifts occurring in the global political economy since the mid-1970s are charted, particularly the massive explosion of the financial sector. These developments have, in turn, rendered commercial real estate a pure financial asset. It is argued that it is this mechanism that spurred the frenetic speculation and overinvestment in the property sector throughout much of the 1980s. This was especially so at London Docklands as investment activities there were further catalysed by an urban and economic policy that endorsed market-driven, speculative short-term practices. The contradictions and instabilities this process engendered at Canary Wharf itself, and how the ensuing 'fallout' has been minimised and legitimated in the United Kingdom through effective nationalisation are examined. The paper is concluded with a discussion on the implications the debacle has for critical theory and progressive politics},
author = {Albrecher, Hansj{\"{o}}rg and Mayer, Philipp and Schoutens, Wim and Tistaert, Jurgen},
journal = {Wilmott},
title = {{The little Heston trap}},
year = {2007}
}
@article{and08,
abstract = {Comment: Exact Heston moments ...},
author = {Andersen, Leif},
doi = {10.21314/jcf.2008.189},
issn = {14601559},
journal = {The Journal of Computational Finance},
title = {{Simple and efficient simulation of the Heston stochastic volatility model}},
year = {2008}
}
@article{che07,
abstract = {Because of the complexity of the modern financial derivatives, like option contracts, prac- titioners heavily rely on mathematical models to price the derivatives. It is known that the classical Black-Scholes option pricing model is not capable of pricing without a significant bias. Numerous model extensions have been introduced in recent years and in this thesis we discuss several of them. To improve the understanding of the dynamics of the future uncer- tainty of asset prices, which is measured in volatility, and its impact on risk-free ‘hedged' portfolios, the stochastic volatility models have emerged in the last decade of the previous century. Within the big family of Stochastic volatility models, the Heston model (one of the many stochastic volatility models) has become a new industrial standard in the domain of exotic equity derivative. Its popularity comes from the fact that the Heston model can price European options highly efficiently by means of the so-called Fast Fourier Transform (FFT) algorithm. Advanced model requires equally sophisticated empirical implementation, in which stage the calibration problem comes in. Since the Heston model contains several undetermined parameters that need to be fitted to the present financial market data. This usually leads to an optimization problem, as calibration implies that the ‘distance' between market and (Heston) mathematical model prices should be minimized. The major difficulty (the one we describe in detail in this thesis) is that the optimization problem is typically ill-posed: The commonly used methods may generate unstable parameters through time, or cannot produce a sufficient fit to the market prices. Here we propose a novel multilevel-structured global optimization procedure, called the Hybrid Stochastic Approximation Search. In this algorithm, we especially contribute with two distinctMarkov processes: The first oneWang- Landau algorithm is capable of leaving local optima, in which common gradient-based optimizationmethods would stagnate in their convergence. At the same time, this algorithm is not as costly as common global optimization algorithms are; Secondly, we propose to include a technique called ‘Partial resampling' in order to reduce big fluctuations produced by the first level and steering the steps through the local dynamics of the optimization landscape. The optimization method is called a ‘Stochastic Approximation' because the Wang- Landau is a controlled Markov Chain guided by the historical samples in the parameter space. These two processes are combined in a multi-level structure where level one, based on the Wang-Landau algorithm ensures a global search, and level two, the partial resampling, increases the efficiency by steering the algorithm with problem specific information. With the calibrated Heston model, we obtain a satisfactory low pricing error for basic ‘plain vanilla' options with parameters that are, to a large extent, stationary, i.e., not depending on time. A local enhancement of calibration can be made by allowing certain parameters to be mildly dependent on time. Next to this main contribution we considered it important to also present the typical use of these mathematical pricing models, and in particular the stochastic volatility models, in financial practice. Therefore, a chapter is reserved for the explanation of the pricing of exotic contract as well as for the hedging of a portfolio, as it occurs in practice. We focus here on the so-called ‘hedge ratios' that are implied by the Heston model and derive analytical solutions for financial contracts that are considered to be volatility sensitive, like cliquets and variance swaps.},
author = {Bin, Chen},
journal = {Master's thesis, Department of Mathematics, Technical {\ldots}},
title = {{Calibration of the heston model with application in derivative pricing and hedging}},
url = {http://ta.twi.tudelft.nl/mf/users/oosterle/oosterlee/chen.pdf},
year = {2007}
}
@article{bs73,
abstract = {If options are correctly priced in the market, it should not be possible to make sure profits by creating portfolios of long and short positions in options and their underlying stocks. Using this principle, a theoretical valuation formula for options is derived. Since almost all corporate liabilities can be viewed as combinations of options, the formula and the analysis that led to it are also applicable to corporate liabilities such as common stock, corporate bonds, and warrants. In particular, the formula can be used to derive the discount that should be applied to a corporate bond because of the possibility of default.},
author = {Black, Fischer and Scholes, Myron},
doi = {10.1086/260062},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/bs73.pdf:pdf},
issn = {1537534X},
journal = {Journal of Political Economy},
number = {3},
pages = {637--657},
publisher = {University of Chicago Press},
title = {{The pricing of options and corporate liabilities}},
volume = {81},
year = {1973}
}
@article{car02,
abstract = {We investigate the importance of diffusion and jumps in a new model for asset returns. In contrast to standard models, we allow for jump components displaying finite or infinite activity and variation. Empirical investigations of time series indicate that index dynamics are devoid of a diffusion component, which may be present in the dynamics of individual stocks. This leads to the conjecture, confirmed on options data, that the risk-neutral process should be free of a diffusion component. We conclude that the statistical and risk-neutral processes for equity prices are pure jump processes of infinite activity and finite variation.},
author = {Carr, Peter and Geman, H{\'{e}}lyette and Madan, Dilip B. and Vor, Marc},
doi = {10.1086/338705},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/car02.pdf:pdf},
issn = {00219398},
journal = {Journal of Business},
month = {apr},
number = {2},
pages = {305--332},
title = {{The Fine Structure of Asset Returns: An Empirical Investigation}},
volume = {75},
year = {2002}
}
@article{car99,
abstract = {This paper shows how the fast Fourier transform may be used to value options when the characteristic function of the return is known analytically.},
author = {Carr, Peter and Madan, Dilip},
doi = {10.21314/jcf.1999.043},
issn = {14601559},
journal = {The Journal of Computational Finance},
number = {4},
pages = {61--73},
publisher = {Incisive Media},
title = {{Option valuation using the fast Fourier transform}},
volume = {2},
year = {1999}
}
@article{cat08,
abstract = {Shannon wavelets are studied together with their differential properties (known as connection coefficients). It is shown that the Shannon sampling theorem can be considered in a more general approach suitable for analyzing functions ranging in multifrequency bands. This generalization coincides with the Shannon wavelet reconstruction of L2 (ℝ;) functions. The differential properties of Shannon wavelets are also studied through the connection coefficients. It is shown that Shannon wavelets are C ∞ -functions and their any order derivatives can be analytically defined by some kind of a finite hypergeometric series. These coefficients make it possible to define the wavelet reconstruction of the derivatives of the C ℓ -functions.},
author = {Cattani, Carlo},
doi = {10.1155/2008/164808},
issn = {1024123X},
journal = {Mathematical Problems in Engineering},
title = {{Shannon wavelets theory}},
volume = {2008},
year = {2008}
}
@article{cla11,
author = {Clark, I},
journal = {Chichester: Wiley},
title = {{Foreign exchange option pricing: A practitioner's guide}},
year = {2011}
}
@article{con04,
author = {Cont, R and Tankov, P},
journal = {Chapman and Hall},
title = {{Financial Modelling with Jump Processes}},
year = {2004}
}
@article{dau92,
author = {Daubechies, I},
journal = {CBMS-NSF Reg. Conf. Ser. Appl. Math.},
title = {{Ten Lectures on Wavelets}},
year = {1992}
}
@article{rol10,
abstract = {This paper proves that the log-spot in the Heston model has a C∞ density and gives an expression of this density as an infinite convolution of Bessel type densities. Such properties are deduced from a factorization of the characteristic function, mainly obtained through an analysis of the complex moment generating function. As an application a new algorithm to simulate spot is developed. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {{del Ba{\~{n}}o Rollin}, Sebastian and Ferreiro-Castilla, Albert and Utzet, Frederic},
doi = {10.1016/j.spa.2010.06.003},
issn = {03044149},
journal = {Stochastic Processes and their Applications},
keywords = {Bessel random variables,Characteristic function,Heston volatility model},
title = {{On the density of log-spot in the Heston volatility model}},
year = {2010}
}
@article{rol09,
abstract = {A new expression for the characteristic function of log-spot in Heston model is presented. This expression more clearly exhibits its properties as an analytic characteristic function and allows us to compute the exact domain of the moment generating function. This result is then applied to the volatility smile at extreme strikes and to the control of the moments of spot. We also give a factorization of the moment generating function as product of Bessel type factors, and an approximating sequence to the law of log-spot is deduced.},
archivePrefix = {arXiv},
arxivId = {0902.2154},
author = {{del Ba{\~{n}}o Rollin}, Sebastian and Ferreiro-Castilla, Albert and Utzet, Frederic},
eprint = {0902.2154},
journal = {working paper},
keywords = {2000,60e10,60h10,91b28,bessel random variables,c65,characteristic function,extreme strikes,heston volatility model,jel classification g13,mathematics subject classification},
title = {{A new look at the Heston characteristic function}},
year = {2009}
}
@article{Fang2008,
abstract = {Here we develop an option pricing method for European options based on the Fourier-cosine series and call it the COS method. The key insight is in the close relation of the characteristic function with the series coefficients of the Fourier-cosine expansion of the density function. In most bcases, the convergence rate of the COS method is exponential and the computational complexity is linear. Its range of application covers underlying asset processes for which the characteristic function is known and various types of option contracts. We will present the method and its applications in two separate parts. The first one is this paper, where we deal with European options in particular. In a follow-up paper we will present its application to options with early-exercise features. {\textcopyright} 2008 Society for Industrial and Applied Mathematics.},
author = {Fang, F. and Oosterlee, C. W.},
doi = {10.1137/080718061},
issn = {10648275},
journal = {SIAM Journal on Scientific Computing},
keywords = {Cosine expansion,European options,Fourier-,Option pricing},
number = {2},
pages = {826--848},
title = {{A novel pricing method for european options based on fourier-cosine series expansions}},
volume = {31},
year = {2008}
}
@article{fer13,
abstract = {For the calibration of the parameters in static and dynamic SABR stochastic volatility models, we propose the application of the GPU technology to the Simulated Annealing global optimization algorithm and to the Monte Carlo simulation. This calibration has been performed for EURO STOXX 50 index and EUR/USD exchange rate with an asymptotic formula for volatility or Monte Carlo simulation. Moreover, in the dynamic model we propose an original more general expression for the functional parameters, specially well suited for the EUR/USD exchange rate case. Numerical results illustrate the expected behavior of both SABR models and the accuracy of the calibration. In terms of computational time, when the asymptotic formula for volatility is used the speedup with respect to CPU computation is around 200 with one GPU. Furthermore, GPU technology allows the use of Monte Carlo simulation for calibration purposes, the computational time with CPU being prohibitive. {\textcopyright} 2013 IMACS.},
author = {Fern{\'{a}}ndez, J. L. and Ferreiro, A. M. and Garc{\'{i}}a-Rodr{\'{i}}guez, J. A. and Leitao, A. and L{\'{o}}pez-Salas, J. G. and V{\'{a}}zquez, C.},
doi = {10.1016/j.matcom.2013.05.007},
issn = {03784754},
journal = {Mathematics and Computers in Simulation},
keywords = {CUDA,Calibration,GPUs,Parallel Simulated Annealing,SABR volatility model},
pages = {55--75},
title = {{Static and dynamic SABR stochastic volatility models: Calibration and option pricing using GPUs}},
volume = {94},
year = {2013}
}
@techreport{flo20,
abstract = {This note shows that the cosine expansion based on the Vieta formula is equivalent to a discretization of the Parseval identity. We then evaluate the use of simple direct algorithms to compute the Shannon coefficients for the payoff. Finally, we explore the efficiency of a Filon quadrature instead of the Vieta formula for the coefficients related to the probability density function.},
author = {Floc'h, Fabien Le},
institution = {arXiv.org},
month = {may},
title = {{Notes on the SWIFT method based on Shannon Wavelets for Option Pricing}},
type = {Papers},
url = {https://ideas.repec.org/p/arx/papers/2005.13252.html},
year = {2020}
}
@inproceedings{fftw3,
abstract = {FFTW is an implementation of the discrete Fourier transform (DFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with hand-optimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific single-instruction, multiple-data (SIMD) instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm. {\textcopyright} 2005 IEEE.},
author = {Frigo, Matteo and Johnson, Steven G.},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2004.840301},
issn = {00189219},
keywords = {Adaptive software,Cosine transform,Fast Fourier transform (FFT),Fourier transform,Hartley transform,I/O tensor},
title = {{The design and implementation of FFTW3}},
year = {2005}
}
@article{gat06,
author = {Gatheral, J},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/gat06.pdf:pdf},
journal = {Finance},
title = {{The volatility surface: A practitioner's guide}},
volume = {357},
year = {2006}
}
@article{ge12,
abstract = {The quickly moving market data in the finance industry requires a frequent parameter identification of the corresponding financial market models. In this paper we apply a special sequential quadratic programming algorithm to the calibration of typical equity market models. As it turns out, the projection of the iterates onto the feasible set can be efficiently computed by solving a semidefinite programming problem. Combining this approach with a Gauss-Newton framework leads to an efficient algorithm which allows to calibrate e.g. Heston's stochastic volatility model in less than a half second on a usual 3 GHz desktop PC. Furthermore we present an appropriate regularization technique that stabilizes and significantly speeds up computations if the model parameters are chosen to be time-dependent. {\textcopyright} Springer Science+Business Media, LLC 2010.},
author = {Gerlich, F. and Giese, A. M. and Maruhn, J. H. and Sachs, E. W.},
doi = {10.1007/s10589-010-9369-8},
issn = {09266003},
journal = {Computational Optimization and Applications},
keywords = {Feasibility perturbed sequential quadratic program,Parameter identification,Stochastic volatility models},
month = {apr},
number = {3},
pages = {1137--1161},
title = {{Parameter identification in financial market models with a feasible point SQP algorithm}},
volume = {51},
year = {2012}
}
@article{gil12,
abstract = {Calibrating option pricing models to market prices often leads to optimisation problems to which standard methods (such as those based on gradients) cannot be applied.We investigate two models: Heston's stochastic volatility model, and Bates's model which also includes jumps. We discuss how to price options under these models, and how to calibrate the parameters of the models with heuristic techniques. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {Gilli, Manfred and Schumann, Enrico},
doi = {10.1007/978-3-642-23336-4_2},
isbn = {9783642233357},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
title = {{Calibrating option pricing models with heuristics}},
year = {2011}
}
@article{gil12_2,
abstract = {There is a large number of optimisation problems in theoretical and applied finance that are difficult to solve as they exhibit multiple local optima or are not 'well-behaved' in other ways (e. g., discontinuities in the objective function). One way to deal with such problems is to adjust and to simplify them, for instance by dropping constraints, until they can be solved with standard numerical methods. We argue that an alternative approach is the application of optimisation heuristics like Simulated Annealing or Genetic Algorithms. These methods have been shown to be capable of handling non-convex optimisation problems with all kinds of constraints. To motivate the use of such techniques in finance, we present several actual problems where classical methods fail. Next, several well-known heuristic techniques that may be deployed in such cases are described. Since such presentations are quite general, we then describe in some detail how a particular problem, portfolio selection, can be tackled by a particular heuristic method, Threshold Accepting. Finally, the stochastics of the solutions obtained from heuristics are discussed. We show, again for the example from portfolio selection, how this random character of the solutions can be exploited to inform the distribution of computations. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
author = {Gilli, Manfred and Schumann, Enrico},
doi = {10.1007/s10479-011-0862-y},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/gil12{\_}2.pdf:pdf},
issn = {02545330},
journal = {Annals of Operations Research},
keywords = {Financial optimisation,Optimisation heuristics,Portfolio optimisation},
title = {{Heuristic optimisation in financial modelling}},
year = {2012}
}
@article{gla11,
abstract = {We derive an explicit representation of the transitions of the Heston stochastic volatility model and use it for fast and accurate simulation of the model. Of particular interest is the integral of the variance process over an interval, conditional on the level of the variance at the endpoints. We give an explicit representation of this quantity in terms of infinite sums and mixtures of gamma random variables. The increments of the variance process are themselves mixtures of gamma random variables. The representation of the integrated conditional variance applies the Pitman-Yor decomposition of Bessel bridges. We combine this representation with the Broadie-Kaya exact simulation method and use it to circumvent the most time-consuming step in that method. {\textcopyright} 2009 Springer-Verlag.},
author = {Glasserman, Paul and Kim, Kyoung Kuk},
doi = {10.1007/s00780-009-0115-y},
issn = {09492984},
journal = {Finance and Stochastics},
keywords = {60H35,65C05,91B70,C63,G12,G13,Monte Carlo methods,Stochastic volatility model},
title = {{Gamma expansion of the Heston stochastic volatility model}},
year = {2011}
}
@article{Heston1993,
abstract = {I use a new technique to derive a closed-form solu- tionfor the price of a European call option on an asset with stochastic volatility. The model allows arbitrary correlation between volatility and spot- asset returns. I introduce stochastic interest rates and show how to apply the model to bond options and foreign currency options. Simulations show that correlation between volatility and the spot asset's price is important for explaining return skewness and strike-price biases in the Black- Scholes (1973) model. The solution technique is based on characteristic functions and can be applied to other problems.},
author = {Heston, Steven L.},
doi = {10.1093/rfs/6.2.327},
issn = {0893-9454},
journal = {Review of Financial Studies},
title = {{A Closed-Form Solution for Options with Stochastic Volatility with Applications to Bond and Currency Options}},
year = {1993}
}
@book{hul09,
abstract = {Updated and revised to reflect the most current information, this introduction to futures and options markets is ideal for those with a limited background in mathematics. Based on Hull's Options, Futures and Other Derivatives, one of the best-selling books on Wall Street, this book presents an accessible overview of the topic without the use of calculus. Packed with numerical samples and accounts of real-life situations, the Fifth Edition effectively guides readers through the material while providing them with a host of tangible examples. For professionals with a career in futures and options markets, financial engineering and/or risk management.},
author = {Hull, John},
booktitle = {Pearson},
isbn = {9780132164948},
title = {{Futures, Options and Other Derivatives}},
year = {2009}
}
@article{jac96,
abstract = {This article derives underlying asset risk-neutral probability distributions of European options on the S{\&}P 500 index. Nonparametric methods are used to choose probabilities that minimize an objective function subject to requiring that the probabilities are consistent with observed option and underlying asset prices. Alternative optimization specifications produce approximately the same implied distributions. A new and fast optimization technique for estimating probability distributions based on maximizing the smoothness of the resulting distribution is proposed. Since the crash, the risk-neutral probability of a three (four) standard deviation decline in the index (about -36 percent (-46 percent) over a year) is about 10 (100) times more likely than under the assumption of lognormality.},
author = {Jackwerth, Jens Carsten and Rubinstein, Mark},
doi = {10.1111/j.1540-6261.1996.tb05219.x},
issn = {00221082},
journal = {Journal of Finance},
number = {5},
pages = {1611--1631},
publisher = {Blackwell Publishing Inc.},
title = {{Recovering probability distributions from option prices}},
volume = {51},
year = {1996}
}
@incollection{jan11,
abstract = {The Heston model stands out from the class of stochastic volatility (SV) models mainly for two reasons. Firstly, the process for the volatility is non-negative and mean-reverting, which is what we observe in the markets. Secondly, there exists a fast and easily implemented semi-analytical solution for European options. In this article we adapt the original work of Heston (1993) to a foreign exchange (FX) setting. We discuss the computational aspects of using the semi-analytical formulas, performing Monte Carlo simulations, checking the Feller condition, and option pricing with FFT. In an empirical study we show that the smile of vanilla options can be reproduced by suitably calibrating three out of five model parameters.},
archivePrefix = {arXiv},
arxivId = {1010.1617},
author = {Janek, Agnieszka and Kluge, Tino and Weron, Rafa{\l} and Wystup, Uwe},
booktitle = {Statistical Tools for Finance and Insurance},
doi = {10.1007/978-3-642-18062-0_4},
eprint = {1010.1617},
pages = {133--162},
publisher = {Springer Berlin Heidelberg},
title = {{FX smile in the Heston model}},
year = {2011}
}
@article{kal06,
abstract = {In Hestons stochastic volatility framework Hes93, semi-analytical formul{\ae} for plain vanilla option prices can be derived. Unfortunately, these formul{\ae} require the evaluation of logarithms with complex arguments during the involved inverse Fourier integration step. This gives rise to an inherent numerical instability as a consequence of which most implementations of Hestons formul{\ae} are not robust for moderate to long dated maturities or strong mean reversion. In this article, we propose a new approach to solve this problem which enables the use of Hestons analytics for practically all levels of parameters and even maturities of many decades.},
author = {Kahl, Christian and J, Peter},
journal = {Wilmott Magazine},
title = {{Not-so-complex logarithms in the Heston model}},
year = {2006}
}
@article{lag98,
abstract = {The Nelder-Mead simplex algorithm, first published in 1965, is an enormously popular direct search method for multidimensional unconstrained minimization. Despite its widespread use essentially no theoretical results have been proved explicitly for the Nelder-Mead algorithm. This paper presents convergence properties of the Nelder-Mead algorithm applied to strictly convex functions in dimensions 1 and 2. We prove convergence to a minimizer for dimension 1, and various limited convergence results for dimension 2. A counterexample of McKinnon gives a family of strictly convex functions in two dimensions and a set of initial conditions for which the Nelder-Mead algorithm converges to a nonminimizer. It is not yet known whether the Nelder-Mead method can be proved to converge to a minimizer for a more specialized class of convex functions in two dimensions.},
author = {Lagarias, Jeffrey C. and Reeds, James A. and Wright, Margaret H. and Wright, Paul E.},
doi = {10.1137/S1052623496303470},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/lag98.pdf:pdf},
issn = {10526234},
journal = {SIAM Journal on Optimization},
keywords = {Direct search methods,Nelder-Mead simplex methods,Nonderivative optimization},
title = {{Convergence properties of the Nelder-Mead simplex method in low dimensions}},
year = {1998}
}
@book{tour,
abstract = {Mallat's book is the undisputed reference in this field - it is the only one that covers the essential material in such breadth and depth. - Laurent Demanet, Stanford University The new edition of this classic book gives all the major concepts, techniques and applications of sparse representation, reflecting the key role the subject plays in today's signal processing. The book clearly presents the standard representations with Fourier, wavelet and time-frequency transforms, and the construction of orthogonal bases with fast algorithms. The central concept of sparsity is explained and applied to signal compression, noise reduction, and inverse problems, while coverage is given to sparse representations in redundant dictionaries, super-resolution and compressive sensing applications. Features: * Balances presentation of the mathematics with applications to signal processing * Algorithms and numerical examples are implemented in WaveLab, a MATLAB toolbox * Companion website for instructors and selected solutions and code available for students New in this edition * Sparse signal representations in dictionaries * Compressive sensing, super-resolution and source separation * Geometric image processing with curvelets and bandlets * Wavelets for computer graphics with lifting on surfaces * Time-frequency audio processing and denoising * Image compression with JPEG-2000 * New and updated exercises A Wavelet Tour of Signal Processing: The Sparse Way, third edition, is an invaluable resource for researchers and R{\&}D engineers wishing to apply the theory in fields such as image processing, video processing and compression, bio-sensing, medical imaging, machine vision and communications engineering. Stephane Mallat is Professor in Applied Mathematics at {\'{E}}cole Polytechnique, Paris, France. From 1986 to 1996 he was a Professor at the Courant Institute of Mathematical Sciences at New York University, and between 2001 and 2007, he co-founded and became CEO of an image processing semiconductor company. Includes all the latest developments since the book was published in 1999, including its application to JPEG 2000 and MPEG-4 Algorithms and numerical examples are implemented in Wavelab, a MATLAB toolbox Balances presentation of the mathematics with applications to signal processing. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Mallat, Stephane},
booktitle = {A Wavelet Tour of Signal Processing},
doi = {10.1016/B978-0-12-374370-1.X0001-8},
isbn = {9780123743701},
title = {{A Wavelet Tour of Signal Processing}},
year = {2009}
}
@misc{levmar,
author = {Lourakis, M. I. A.},
title = {{levmar: Levenberg–Marquardt nonlinear least squares al- gorithms in C/C++.}},
url = {http://www.ics.forth.gr/∼lourakis/levmar},
year = {2004}
}
@article{mer73,
author = {Merton, Robert C},
journal = {Bell Journal of Economics and Management Science},
pages = {141--183},
title = {{Theory of rational option pricing}},
volume = {4(1)},
year = {1973}
}
@article{mik03,
abstract = {The paper discusses theoretical properties, shows the performance and presents some extensions of Hestons (1993) stochastic volatility model. The model proposed by Heston extends the Black and Scholes (1993) model and includes it as a special case. Hestons setting take into account non-lognormal distribution of the assets returns, leverage effect, important mean-reverting property of volatility and it remains analytically tractable. The Black-Scholes volatility surfaces generated by Hestons model look like empirical implied volatility surfaces. The complication is related to the risk-neutral valuation concept. It is not possible to build a riskless portfolio if we formulate the statement that the volatility of the asset varies stochastically. This is principally because the volatility is not a tradable security.},
author = {Mikhailov, Sergei and N{\"{o}}gel, Ulrich},
isbn = {0470023511},
journal = {Wilmott Magazine},
keywords = {calibration and some extensions,model implementation,s stochastic volatility,sergei mikhailov,ton,ulrich n{\"{o}}gel},
pages = {74--79},
title = {{Heston ' s Stochastic Volatility Model Implementation , Calibration and Some Extensions}},
volume = {4},
year = {2003}
}
@incollection{mor78,
abstract = {Work performed under the auspices of the U.S. Energy Research and Development Administration},
author = {Mor{\'{e}}, Jorge J.},
doi = {10.1007/bfb0067700},
title = {{The Levenberg-Marquardt algorithm: Implementation and theory}},
year = {1978}
}
@article{pea00,
abstract = {Option prices can be used to construct implied (risk-neutral) distributions, but it remains to be proven whether these are useful either in relation to forecasting subsequent market movements or in revealing investor sentiment. We estimate the implied distribution as a mixture of two lognormals and then test its one-day-ahead forecasting performance, using 1987-97 data on LIFFE's FTSE-100 index options. We find that the two-lognormal method is much better than the one-lognormal (Black/Scholes) approach at fitting observed option prices, but it is only marginally better at predicting out-of-sample prices. A closer analysis of four "crash" periods confirms that the shape of the implied distribution does not anticipate such events but merely reflects their passing. Similarly, during three British elections the implied distributions take on interesting shapes but these are not closely related to prior information about the likely outcomes. In short, while we cannot reject the hypothesis that implied distributions reflect market sentiment, we find that sentiment (thus measured) has little forecasting ability.},
author = {Peake, Charles F.},
doi = {10.2469/dig.v30.n4.786},
issn = {0046-9777},
journal = {CFA Digest},
title = {{How Useful Are Implied Distributions? Evidence from Stock Index Options}},
year = {2000}
}
@article{lapack,
abstract = {LAPACK is a library of Fortran 77 subroutines for solving the most commonly occurring problems in numerical linear algebra. It has been designed to be efficient on a wide range of modern high- performance computers. The name LAPACK is an acronym for Linear Algebra PACKage.},
author = {Planitz, Max and Anderson, E.},
doi = {10.2307/3620088},
issn = {00255572},
journal = {The Mathematical Gazette},
title = {{LAPACK Users Guide}},
year = {1995}
}
@book{sch03,
abstract = {Financial mathematics has recently enjoyed considerable interest on account of its impact on the finance industry. In parallel, the theory of L{\~{A}}vy processes has also seen many exciting developments. These powerful modelling tools allow the user to model more complex phenomena, and are commonly applied to problems in finance. L{\~{A}}vy Processes in Finance: Pricing Financial Derivatives takes a practical approach to describing the theory of L{\~{A}}vy-based models, and features many examples of how they may be used to solve problems in finance. Provides an introduction to the use of L{\~{A}}vy processes in finance. Features many examples using real market data, with emphasis on the pricing of financial derivatives. Covers a number of key topics, including option pricing, Monte Carlo simulations, stochastic volatility, exotic options and interest rate modelling. Includes many figures to illustrate the theory and examples discussed. Avoids unnecessary mathematical formalities. The book is primarily aimed at researchers and postgraduate students of mathematical finance, economics and finance. The range of examples ensures the book will make a valuable reference source for practitioners from the finance industry including risk managers and financial product developers.},
author = {Schoutens, Wim},
booktitle = {L{\'{e}}vy Processes in Finance},
doi = {10.1002/0470870230},
title = {{L{\'{e}}vy Processes in Finance}},
year = {2003}
}
@article{sch04,
abstract = {We show that several advanced equity option models incorporating stochastic volatility can be calibrated very nicely to a realistic option surface. More specifically, we focus on the Heston Stochastic Volatility model (with and without jumps in the stock price process), the Barndorff-Nielsen-Shephard model and L{\'{e}}vy models with stochastic time. All these models are capable of accurately describing the marginal distribution of stock prices or indices and hence lead to almost identical European vanilla option prices. As such, we can hardly discriminate between the different processes on the basis of their smile-conform pricing characteristics. We therefore are tempted applying them to a range of exotics. However, due to the different structure in path-behaviour between these models, the resulting exotics prices can vary significantly. It motivates a further study on how to model the fine stochastic behaviour of assets over time. 1},
author = {Schoutens, Wim and Simons, Erwin and Tistaert, Jurgen},
doi = {10.1002/wilm.42820040216},
issn = {15406962},
journal = {Wilmott},
title = {{A perfect calibration! now what?}},
year = {2004}
}
@article{sha49,
abstract = {A method is developed for representing any communication system geometrically. Messages and the corresponding signals are points in two “function spaces,” and the modulation process is a mapping of one space into the other. Using this representation, a number of results in communication theory are deduced concerning expansion and compression of bandwidth and the threshold effect Formulas are found for the maximum rate of transmission of binary digits over a system when the signal is perturbed by various types of noise. Some of the properties of “ideal” systems which transmit at this maximum rate are discussed. The equivalent number of binary digits per second for certain information sources is calculated. Copyright, 1949, by The Institute of Radio Engineers, Inc.},
author = {Shannon, Claude E.},
doi = {10.1109/JRPROC.1949.232969},
issn = {00968390},
journal = {Proceedings of the IRE},
number = {1},
pages = {10--21},
title = {{Communication in the Presence of Noise}},
volume = {37},
year = {1949}
}
@book{ste11,
abstract = {Handbook of Sinc Numerical Methods presents an ideal road map for handling general numeric problems. Reflecting the author's advances with Sinc since 1995, the text most notably provides a detailed exposition of the Sinc separation of variables method for numerically solving the full range of partial differential equations (PDEs) of interest to scientists and engineers. This new theory, which combines Sinc convolution with the boundary integral equation (IE) approach, makes for exponentially faster convergence to solutions of differential equations. The basis for the approach is the Sinc method of approximating almost every type of operation stemming from calculus via easily computed matrices of very low dimension. The CD-ROM of this handbook contains roughly 450 MATLAB{\textregistered} programs corresponding to exponentially convergent numerical algorithms for solving nearly every computational problem of science and engineering. While the book makes Sinc methods accessible to users wanting to bypass the complete theory, it also offers sufficient theoretical details for readers who do want a full working understanding of this exciting area of numerical analysis.},
author = {Stenger, Frank},
booktitle = {Handbook of Sinc Numerical Methods},
doi = {10.1201/b10375},
isbn = {9781439821596},
month = {apr},
pages = {1--460},
publisher = {CRC Press},
title = {{Handbook of sinc numerical methods}},
year = {2016}
}
@incollection{wil16,
author = {Willmore, Frank T.},
booktitle = {Introduction to Scientific and Technical Computing},
doi = {10.1201/9781315382395},
isbn = {9781315382395},
title = {{Debugging with gdb}},
year = {2016}
}
@article{bor10,
abstract = {We introduce the formalism of generalized Fourier transforms in the context of risk management. We develop a general framework in which to efficiently compute the most popular risk measures, value-at-risk and expected shortfall (also known as conditional value-at-risk). The only ingredient required by our approach is the knowledge of the characteristic function describing the financial data in use. This allows us to extend risk analysis to those non-Gaussian models defined in the Fourier space, such as L{\'{e}}vy noise driven processes and stochastic volatility models. We test our analytical results on data sets coming from various financial indexes, finding that our predictions outperform those provided by the standard log-normal dynamics and are in remarkable agreement with those of the benchmark historical approach. {\textcopyright} IOP Publishing Ltd.},
archivePrefix = {arXiv},
arxivId = {0909.3978},
author = {Bormetti, Giacomo and Cazzola, Valentina and Livan, Giacomo and Montagna, Guido and Nicrosini, Oreste},
doi = {10.1088/1742-5468/2010/01/P01005},
eprint = {0909.3978},
issn = {17425468},
journal = {Journal of Statistical Mechanics: Theory and Experiment},
keywords = {Models of financial markets,Risk measure and management,Stochastic processes},
title = {{A generalized Fourier transform approach to risk measures}},
year = {2010}
}
@article{cui17,
abstract = {This paper presents an algorithm for a complete and efficient calibration of the Heston stochastic volatility model. We express the calibration as a nonlinear least-squares problem. We exploit a suitable representation of the Heston characteristic function and modify it to avoid discontinuities caused by branch switchings of complex functions. Using this representation, we obtain the analytical gradient of the price of a vanilla option with respect to the model parameters, which is the key element of all variants of the objective function. The interdependence between the components of the gradient enables an efficient implementation which is around ten times faster than with a numerical gradient. We choose the Levenberg–Marquardt method to calibrate the model and do not observe multiple local minima reported in previous research. Two-dimensional sections show that the objective function is shaped as a narrow valley with a flat bottom. Our method is the fastest calibration of the Heston model developed so far and meets the speed requirement of practical trading.},
archivePrefix = {arXiv},
arxivId = {1511.08718},
author = {Cui, Yiran and {del Ba{\~{n}}o Rollin}, Sebastian and Germano, Guido},
doi = {10.1016/j.ejor.2017.05.018},
eprint = {1511.08718},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/cui17.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Heston model,Levenberg–Marquardt method,Model calibration,Optimisation,Pricing},
month = {dec},
number = {2},
pages = {625--638},
publisher = {Elsevier B.V.},
title = {{Full and fast calibration of the Heston stochastic volatility model}},
volume = {263},
year = {2017}
}
@article{mar17,
abstract = {We present a pricing method based on Shannon wavelet expansions for early-exercise and discretely-monitored barrier options under exponential L{\'{e}}vy asset dynamics. Shannon wavelets are smooth, and thus approximate the densities that occur in finance well, resulting in exponential convergence. Application of the Fast Fourier Transform yields an efficient implementation and since wavelets give local approximations, the domain boundary errors can be naturally resolved, which is the main improvement over existing methods.},
author = {Maree, S. C. and Ortiz-Gracia, L. and Oosterlee, C. W.},
doi = {10.1007/s00211-016-0858-2},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/mar17.pdf:pdf},
issn = {0029599X},
journal = {Numerische Mathematik},
keywords = {65D30,65T60,91B24},
month = {aug},
number = {4},
pages = {1035--1070},
publisher = {Springer New York LLC},
title = {{Pricing early-exercise and discrete barrier options by Shannon wavelet expansions}},
volume = {136},
year = {2017}
}
@article{Ortiz-Gracia2016,
abstract = {In the search for robust, accurate, and highly efficient financial option valuation techniques, we here present the SWIFT method (Shannon wavelets inverse Fourier technique), based on Shannon wavelets. SWIFT comes with control over approximation errors made by means of sharp quantitative error bounds. The nature of the local Shannon wavelets basis enables us to adaptively determine the proper size of the computational interval. Numerical experiments on European-style options show exponential convergence and confirm the bounds, robustness, and efficiency.},
author = {Ortiz-Gracia, Luis and Oosterlee, Cornelis W.},
doi = {10.1137/15M1014164},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/ort16.pdf:pdf},
issn = {10957197},
journal = {SIAM Journal on Scientific Computing},
keywords = {European options,Fourier transform inversion,Option pricing,Shannon wavelets,Sinus cardinal function,ort16},
mendeley-tags = {ort16},
title = {{A highly efficient shannon wavelet inverse fourier technique for pricing European options}},
year = {2016}
}
@article{moo05,
abstract = {This document covers various aspects the Heston model. The structure and topics covered is as follows: Chapter 1 introduces the model and provides theoretical and graphical motivation for its robustness and hence popularity. It also discusses pricing using the Partial Differential Equation and Equivalent Martingale Measure techniques Chapter 2 discusses how the different components of the model can be evaluated computationally and how this can be achieved with different methods. These methods are then compared to each other. Chapter 3 addresses the calibration problem. Different methods are presented as well as practical implementation, results thereof, and comparisons. All the MATLAB code required to implement the model is provided in the appendix},
author = {Mooley, Nimalin},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/moo05.pdf:pdf},
journal = {University of the Witwatersrand},
title = {{The Heston Model: A Practical Approach with Matlab Code (Bachelor's thesis)}},
year = {2005}
}
@article{chr02,
abstract = {Which loss function should be used when estimating and evaluating option valuation models? Many different functions have been suggested, but no standard has emerged. We emphasize that consistency in the choice of loss functions is crucial. First, for any given model, the loss function used in parameter estimation and model evaluation should be the same, otherwise suboptimal parameter estimates may be obtained. Second, when comparing models, the estimation loss function should be identical across models, otherwise inappropriate comparisons will be made. We illustrate the importance of these issues in an application of the so-called Practitioner Black-Scholes model to S{\&}P 500 index options. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {Christoffersen, Peter and Jacobs, Kris},
doi = {10.1016/j.jfineco.2003.02.001},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/chr02.pdf:pdf},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Implied volatility functions,Out-of-sample forecasting,Parameter stability,Valuation errors},
title = {{The importance of the loss function in option valuation}},
year = {2004}
}
@article{lei18,
author = {A. Leitao, L. Ortiz-Gracia and E.I. Wagner},
journal = {Journal of Computational Science},
title = {{SWIFT valuation of discretely monitored arithmetic Asian options}},
year = {2018},
number = {28},
pages = {120--139}
}