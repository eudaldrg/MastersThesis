@article{car02,
abstract = {We investigate the importance of diffusion and jumps in a new model for asset returns. In contrast to standard models, we allow for jump components displaying finite or infinite activity and variation. Empirical investigations of time series indicate that index dynamics are devoid of a diffusion component, which may be present in the dynamics of individual stocks. This leads to the conjecture, confirmed on options data, that the risk-neutral process should be free of a diffusion component. We conclude that the statistical and risk-neutral processes for equity prices are pure jump processes of infinite activity and finite variation.},
author = {Carr, Peter and Geman, H{\'{e}}lyette and Madan, Dilip B. and Vor, Marc},
doi = {10.1086/338705},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/car02.pdf:pdf},
issn = {00219398},
journal = {Journal of Business},
month = {apr},
number = {2},
pages = {305--332},
title = {{The Fine Structure of Asset Returns: An Empirical Investigation}},
volume = {75},
year = {2002}
}
@article{cla11,
author = {Clark, I},
journal = {Chichester: Wiley},
title = {{Foreign exchange option pricing: A practitioner's guide}},
year = {2011}
}
@article{gat06,
author = {Gatheral, J},
journal = {Finance},
title = {{The volatility surface: A practitioner's guide}},
volume = {357},
year = {2006}
}
@article{mer73,
author = {Merton, Robert C},
journal = {Bell Journal of Economics and Management Science},
pages = {141--183},
title = {{Theory of rational option pricing}},
volume = {4(1)},
year = {1973}
}
@article{con04,
author = {Cont, R and Tankov, P},
journal = {Chapman and Hall},
title = {{Financial Modelling with Jump Processes}},
year = {2004}
}
@article{dau92,
author = {Daubechies, I},
journal = {CBMS-NSF Reg. Conf. Ser. Appl. Math.},
title = {{Ten Lectures on Wavelets}},
year = {1992}
}
@article{abr15_1,
abstract = {We present a rational approximation for rapid and accurate computation of the Voigt function, obtained by sampling and residue calculus. The computational test reveals that with only {\$}16{\$} summation terms this approximation provides average accuracy {\$}{\{}10{\^{}}{\{} - 14{\}}{\}}{\$} over a wide domain of practical interest {\$}0 {\textless} x {\textless} 40,000{\$} and {\$}{\{}10{\^{}}{\{} - 4{\}}{\}} {\textless} y {\textless} {\{}10{\^{}}2{\}}{\$} for applications using the HITRAN molecular spectroscopic database. The proposed rational approximation takes less than half the computation time of that required by Weideman$\backslash$text{\{}'{\}}s rational approximation. Algorithmic stability is achieved due to absence of the poles at {\$}y \backslashgeqslant 0{\$} and {\$} - \backslashinfty {\textless} x {\textless} \backslashinfty {\$}.},
archivePrefix = {arXiv},
arxivId = {1504.00322},
author = {Abrarov, Sanjar M. and Quine, Brendan M.},
doi = {10.5539/jmr.v7n2p163},
eprint = {1504.00322},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/abr15pdf.pdf:pdf},
issn = {1916-9795},
journal = {Journal of Mathematics Research},
month = {jun},
number = {2},
pages = {163},
publisher = {Canadian Center of Science and Education},
title = {{A Rational Approximation for Efficient Computation of the Voigt Function in Quantitative Spectroscopy}},
volume = {7},
year = {2015}
}
@incollection{jan11,
abstract = {The Heston model stands out from the class of stochastic volatility (SV) models mainly for two reasons. Firstly, the process for the volatility is non-negative and mean-reverting, which is what we observe in the markets. Secondly, there exists a fast and easily implemented semi-analytical solution for European options. In this article we adapt the original work of Heston (1993) to a foreign exchange (FX) setting. We discuss the computational aspects of using the semi-analytical formulas, performing Monte Carlo simulations, checking the Feller condition, and option pricing with FFT. In an empirical study we show that the smile of vanilla options can be reproduced by suitably calibrating three out of five model parameters.},
archivePrefix = {arXiv},
arxivId = {1010.1617},
author = {Janek, Agnieszka and Kluge, Tino and Weron, Rafa{\l} and Wystup, Uwe},
booktitle = {Statistical Tools for Finance and Insurance},
doi = {10.1007/978-3-642-18062-0_4},
eprint = {1010.1617},
pages = {133--162},
publisher = {Springer Berlin Heidelberg},
title = {{FX smile in the Heston model}},
year = {2011}
}
@article{Abrarov2015,
abstract = {A new sampling methodology based on an incomplete cosine expansion series is presented as an alternative to the traditional sinc function approach. Numerical integration shows that this methodology is efficient and practical. Applying the incomplete cosine expansion we obtain a rational approximation of the complex error function that with the same number of the summation terms provides an accuracy exceeding the Weideman's approximation accuracy by several orders of the magnitude. Application of the expansion results in an integration consisting of elementary function terms only. Consequently, this approach can be advantageous for accurate and rapid computation.},
archivePrefix = {arXiv},
arxivId = {1407.0533},
author = {Abrarov, S. M. and Quine, B. M.},
doi = {10.1016/j.amc.2015.01.072},
eprint = {1407.0533},
issn = {00963003},
journal = {Applied Mathematics and Computation},
keywords = {Complex error function,Numerical integration,Rational approximation,Sampling,Sinc function,Voigt function},
month = {may},
pages = {425--435},
publisher = {Elsevier Inc.},
title = {{Sampling by incomplete cosine expansion of the sinc function: Application to the Voigt/complex error function}},
volume = {258},
year = {2015}
}
@article{lag98,
abstract = {The Nelder-Mead simplex algorithm, first published in 1965, is an enormously popular direct search method for multidimensional unconstrained minimization. Despite its widespread use essentially no theoretical results have been proved explicitly for the Nelder-Mead algorithm. This paper presents convergence properties of the Nelder-Mead algorithm applied to strictly convex functions in dimensions 1 and 2. We prove convergence to a minimizer for dimension 1, and various limited convergence results for dimension 2. A counterexample of McKinnon gives a family of strictly convex functions in two dimensions and a set of initial conditions for which the Nelder-Mead algorithm converges to a nonminimizer. It is not yet known whether the Nelder-Mead method can be proved to converge to a minimizer for a more specialized class of convex functions in two dimensions.},
author = {Lagarias, Jeffrey C. and Reeds, James A. and Wright, Margaret H. and Wright, Paul E.},
doi = {10.1137/S1052623496303470},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/lag98.pdf:pdf},
issn = {10526234},
journal = {SIAM Journal on Optimization},
keywords = {Direct search methods,Nelder-Mead simplex methods,Nonderivative optimization},
title = {{Convergence properties of the Nelder-Mead simplex method in low dimensions}},
year = {1998}
}
@article{gil12_2,
abstract = {There is a large number of optimisation problems in theoretical and applied finance that are difficult to solve as they exhibit multiple local optima or are not 'well-behaved' in other ways (e. g., discontinuities in the objective function). One way to deal with such problems is to adjust and to simplify them, for instance by dropping constraints, until they can be solved with standard numerical methods. We argue that an alternative approach is the application of optimisation heuristics like Simulated Annealing or Genetic Algorithms. These methods have been shown to be capable of handling non-convex optimisation problems with all kinds of constraints. To motivate the use of such techniques in finance, we present several actual problems where classical methods fail. Next, several well-known heuristic techniques that may be deployed in such cases are described. Since such presentations are quite general, we then describe in some detail how a particular problem, portfolio selection, can be tackled by a particular heuristic method, Threshold Accepting. Finally, the stochastics of the solutions obtained from heuristics are discussed. We show, again for the example from portfolio selection, how this random character of the solutions can be exploited to inform the distribution of computations. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
author = {Gilli, Manfred and Schumann, Enrico},
doi = {10.1007/s10479-011-0862-y},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/gil12{\_}2.pdf:pdf},
issn = {02545330},
journal = {Annals of Operations Research},
keywords = {Financial optimisation,Optimisation heuristics,Portfolio optimisation},
title = {{Heuristic optimisation in financial modelling}},
year = {2012}
}
@article{gil12,
abstract = {Calibrating option pricing models to market prices often leads to optimisation problems to which standard methods (such as those based on gradients) cannot be applied.We investigate two models: Heston's stochastic volatility model, and Bates's model which also includes jumps. We discuss how to price options under these models, and how to calibrate the parameters of the models with heuristic techniques. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
author = {Gilli, Manfred and Schumann, Enrico},
doi = {10.1007/978-3-642-23336-4_2},
isbn = {9783642233357},
issn = {1860949X},
journal = {Studies in Computational Intelligence},
title = {{Calibrating option pricing models with heuristics}},
year = {2011}
}
@book{tour,
abstract = {Mallat's book is the undisputed reference in this field - it is the only one that covers the essential material in such breadth and depth. - Laurent Demanet, Stanford University The new edition of this classic book gives all the major concepts, techniques and applications of sparse representation, reflecting the key role the subject plays in today's signal processing. The book clearly presents the standard representations with Fourier, wavelet and time-frequency transforms, and the construction of orthogonal bases with fast algorithms. The central concept of sparsity is explained and applied to signal compression, noise reduction, and inverse problems, while coverage is given to sparse representations in redundant dictionaries, super-resolution and compressive sensing applications. Features: * Balances presentation of the mathematics with applications to signal processing * Algorithms and numerical examples are implemented in WaveLab, a MATLAB toolbox * Companion website for instructors and selected solutions and code available for students New in this edition * Sparse signal representations in dictionaries * Compressive sensing, super-resolution and source separation * Geometric image processing with curvelets and bandlets * Wavelets for computer graphics with lifting on surfaces * Time-frequency audio processing and denoising * Image compression with JPEG-2000 * New and updated exercises A Wavelet Tour of Signal Processing: The Sparse Way, third edition, is an invaluable resource for researchers and R{\&}D engineers wishing to apply the theory in fields such as image processing, video processing and compression, bio-sensing, medical imaging, machine vision and communications engineering. Stephane Mallat is Professor in Applied Mathematics at {\'{E}}cole Polytechnique, Paris, France. From 1986 to 1996 he was a Professor at the Courant Institute of Mathematical Sciences at New York University, and between 2001 and 2007, he co-founded and became CEO of an image processing semiconductor company. Includes all the latest developments since the book was published in 1999, including its application to JPEG 2000 and MPEG-4 Algorithms and numerical examples are implemented in Wavelab, a MATLAB toolbox Balances presentation of the mathematics with applications to signal processing. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Mallat, Stephane},
booktitle = {A Wavelet Tour of Signal Processing},
doi = {10.1016/B978-0-12-374370-1.X0001-8},
isbn = {9780123743701},
title = {{A Wavelet Tour of Signal Processing}},
year = {2009}
}
@article{bs73,
abstract = {If options are correctly priced in the market, it should not be possible to make sure profits by creating portfolios of long and short positions in options and their underlying stocks. Using this principle, a theoretical valuation formula for options is derived. Since almost all corporate liabilities can be viewed as combinations of options, the formula and the analysis that led to it are also applicable to corporate liabilities such as common stock, corporate bonds, and warrants. In particular, the formula can be used to derive the discount that should be applied to a corporate bond because of the possibility of default.},
author = {Black, Fischer and Scholes, Myron},
doi = {10.1086/260062},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/bs73.pdf:pdf},
issn = {1537534X},
journal = {Journal of Political Economy},
number = {3},
pages = {637--657},
publisher = {University of Chicago Press},
title = {{The pricing of options and corporate liabilities}},
volume = {81},
year = {1973}
}
@article{che07,
abstract = {Because of the complexity of the modern financial derivatives, like option contracts, prac- titioners heavily rely on mathematical models to price the derivatives. It is known that the classical Black-Scholes option pricing model is not capable of pricing without a significant bias. Numerous model extensions have been introduced in recent years and in this thesis we discuss several of them. To improve the understanding of the dynamics of the future uncer- tainty of asset prices, which is measured in volatility, and its impact on risk-free ‘hedged' portfolios, the stochastic volatility models have emerged in the last decade of the previous century. Within the big family of Stochastic volatility models, the Heston model (one of the many stochastic volatility models) has become a new industrial standard in the domain of exotic equity derivative. Its popularity comes from the fact that the Heston model can price European options highly efficiently by means of the so-called Fast Fourier Transform (FFT) algorithm. Advanced model requires equally sophisticated empirical implementation, in which stage the calibration problem comes in. Since the Heston model contains several undetermined parameters that need to be fitted to the present financial market data. This usually leads to an optimization problem, as calibration implies that the ‘distance' between market and (Heston) mathematical model prices should be minimized. The major difficulty (the one we describe in detail in this thesis) is that the optimization problem is typically ill-posed: The commonly used methods may generate unstable parameters through time, or cannot produce a sufficient fit to the market prices. Here we propose a novel multilevel-structured global optimization procedure, called the Hybrid Stochastic Approximation Search. In this algorithm, we especially contribute with two distinctMarkov processes: The first oneWang- Landau algorithm is capable of leaving local optima, in which common gradient-based optimizationmethods would stagnate in their convergence. At the same time, this algorithm is not as costly as common global optimization algorithms are; Secondly, we propose to include a technique called ‘Partial resampling' in order to reduce big fluctuations produced by the first level and steering the steps through the local dynamics of the optimization landscape. The optimization method is called a ‘Stochastic Approximation' because the Wang- Landau is a controlled Markov Chain guided by the historical samples in the parameter space. These two processes are combined in a multi-level structure where level one, based on the Wang-Landau algorithm ensures a global search, and level two, the partial resampling, increases the efficiency by steering the algorithm with problem specific information. With the calibrated Heston model, we obtain a satisfactory low pricing error for basic ‘plain vanilla' options with parameters that are, to a large extent, stationary, i.e., not depending on time. A local enhancement of calibration can be made by allowing certain parameters to be mildly dependent on time. Next to this main contribution we considered it important to also present the typical use of these mathematical pricing models, and in particular the stochastic volatility models, in financial practice. Therefore, a chapter is reserved for the explanation of the pricing of exotic contract as well as for the hedging of a portfolio, as it occurs in practice. We focus here on the so-called ‘hedge ratios' that are implied by the Heston model and derive analytical solutions for financial contracts that are considered to be volatility sensitive, like cliquets and variance swaps.},
author = {Bin, Chen},
journal = {Master's thesis, Department of Mathematics, Technical {\ldots}},
title = {{Calibration of the heston model with application in derivative pricing and hedging}},
url = {http://ta.twi.tudelft.nl/mf/users/oosterle/oosterlee/chen.pdf},
year = {2007}
}
@article{ge12,
abstract = {The quickly moving market data in the finance industry requires a frequent parameter identification of the corresponding financial market models. In this paper we apply a special sequential quadratic programming algorithm to the calibration of typical equity market models. As it turns out, the projection of the iterates onto the feasible set can be efficiently computed by solving a semidefinite programming problem. Combining this approach with a Gauss-Newton framework leads to an efficient algorithm which allows to calibrate e.g. Heston's stochastic volatility model in less than a half second on a usual 3 GHz desktop PC. Furthermore we present an appropriate regularization technique that stabilizes and significantly speeds up computations if the model parameters are chosen to be time-dependent. {\textcopyright} Springer Science+Business Media, LLC 2010.},
author = {Gerlich, F. and Giese, A. M. and Maruhn, J. H. and Sachs, E. W.},
doi = {10.1007/s10589-010-9369-8},
issn = {09266003},
journal = {Computational Optimization and Applications},
keywords = {Feasibility perturbed sequential quadratic program,Parameter identification,Stochastic volatility models},
month = {apr},
number = {3},
pages = {1137--1161},
title = {{Parameter identification in financial market models with a feasible point SQP algorithm}},
volume = {51},
year = {2012}
}
@article{mar17,
abstract = {We present a pricing method based on Shannon wavelet expansions for early-exercise and discretely-monitored barrier options under exponential L{\'{e}}vy asset dynamics. Shannon wavelets are smooth, and thus approximate the densities that occur in finance well, resulting in exponential convergence. Application of the Fast Fourier Transform yields an efficient implementation and since wavelets give local approximations, the domain boundary errors can be naturally resolved, which is the main improvement over existing methods.},
author = {Maree, S. C. and Ortiz-Gracia, L. and Oosterlee, C. W.},
doi = {10.1007/s00211-016-0858-2},
issn = {0029599X},
journal = {Numerische Mathematik},
keywords = {65D30,65T60,91B24},
month = {aug},
number = {4},
pages = {1035--1070},
publisher = {Springer New York LLC},
title = {{Pricing early-exercise and discrete barrier options by Shannon wavelet expansions}},
volume = {136},
year = {2017}
}
@article{mik03,
abstract = {The paper discusses theoretical properties, shows the performance and presents some extensions of Hestons (1993) stochastic volatility model. The model proposed by Heston extends the Black and Scholes (1993) model and includes it as a special case. Hestons setting take into account non-lognormal distribution of the assets returns, leverage effect, important mean-reverting property of volatility and it remains analytically tractable. The Black-Scholes volatility surfaces generated by Hestons model look like empirical implied volatility surfaces. The complication is related to the risk-neutral valuation concept. It is not possible to build a riskless portfolio if we formulate the statement that the volatility of the asset varies stochastically. This is principally because the volatility is not a tradable security.},
author = {Mikhailov, Sergei and N{\"{o}}gel, Ulrich},
isbn = {0470023511},
journal = {Wilmott Magazine},
keywords = {calibration and some extensions,model implementation,s stochastic volatility,sergei mikhailov,ton,ulrich n{\"{o}}gel},
pages = {74--79},
title = {{Heston ' s Stochastic Volatility Model Implementation , Calibration and Some Extensions}},
volume = {4},
year = {2003}
}
@article{cat08,
abstract = {Shannon wavelets are studied together with their differential properties (known as connection coefficients). It is shown that the Shannon sampling theorem can be considered in a more general approach suitable for analyzing functions ranging in multifrequency bands. This generalization coincides with the Shannon wavelet reconstruction of L2 (ℝ;) functions. The differential properties of Shannon wavelets are also studied through the connection coefficients. It is shown that Shannon wavelets are C ∞ -functions and their any order derivatives can be analytically defined by some kind of a finite hypergeometric series. These coefficients make it possible to define the wavelet reconstruction of the derivatives of the C ℓ -functions.},
author = {Cattani, Carlo},
doi = {10.1155/2008/164808},
issn = {1024123X},
journal = {Mathematical Problems in Engineering},
title = {{Shannon wavelets theory}},
volume = {2008},
year = {2008}
}
@book{ste11,
abstract = {Handbook of Sinc Numerical Methods presents an ideal road map for handling general numeric problems. Reflecting the author's advances with Sinc since 1995, the text most notably provides a detailed exposition of the Sinc separation of variables method for numerically solving the full range of partial differential equations (PDEs) of interest to scientists and engineers. This new theory, which combines Sinc convolution with the boundary integral equation (IE) approach, makes for exponentially faster convergence to solutions of differential equations. The basis for the approach is the Sinc method of approximating almost every type of operation stemming from calculus via easily computed matrices of very low dimension. The CD-ROM of this handbook contains roughly 450 MATLAB{\textregistered} programs corresponding to exponentially convergent numerical algorithms for solving nearly every computational problem of science and engineering. While the book makes Sinc methods accessible to users wanting to bypass the complete theory, it also offers sufficient theoretical details for readers who do want a full working understanding of this exciting area of numerical analysis.},
author = {Stenger, Frank},
booktitle = {Handbook of Sinc Numerical Methods},
doi = {10.1201/b10375},
isbn = {9781439821596},
month = {apr},
pages = {1--460},
publisher = {CRC Press},
title = {{Handbook of sinc numerical methods}},
year = {2016}
}
@article{sha49,
abstract = {A method is developed for representing any communication system geometrically. Messages and the corresponding signals are points in two “function spaces,” and the modulation process is a mapping of one space into the other. Using this representation, a number of results in communication theory are deduced concerning expansion and compression of bandwidth and the threshold effect Formulas are found for the maximum rate of transmission of binary digits over a system when the signal is perturbed by various types of noise. Some of the properties of “ideal” systems which transmit at this maximum rate are discussed. The equivalent number of binary digits per second for certain information sources is calculated. Copyright, 1949, by The Institute of Radio Engineers, Inc.},
author = {Shannon, Claude E.},
doi = {10.1109/JRPROC.1949.232969},
issn = {00968390},
journal = {Proceedings of the IRE},
number = {1},
pages = {10--21},
title = {{Communication in the Presence of Noise}},
volume = {37},
year = {1949}
}
@article{car99,
abstract = {This paper shows how the fast Fourier transform may be used to value options when the characteristic function of the return is known analytically.},
author = {Carr, Peter and Madan, Dilip},
doi = {10.21314/jcf.1999.043},
issn = {14601559},
journal = {The Journal of Computational Finance},
number = {4},
pages = {61--73},
publisher = {Incisive Media},
title = {{Option valuation using the fast Fourier transform}},
volume = {2},
year = {1999}
}
@article{cui17,
abstract = {This paper presents an algorithm for a complete and efficient calibration of the Heston stochastic volatility model. We express the calibration as a nonlinear least-squares problem. We exploit a suitable representation of the Heston characteristic function and modify it to avoid discontinuities caused by branch switchings of complex functions. Using this representation, we obtain the analytical gradient of the price of a vanilla option with respect to the model parameters, which is the key element of all variants of the objective function. The interdependence between the components of the gradient enables an efficient implementation which is around ten times faster than with a numerical gradient. We choose the Levenberg–Marquardt method to calibrate the model and do not observe multiple local minima reported in previous research. Two-dimensional sections show that the objective function is shaped as a narrow valley with a flat bottom. Our method is the fastest calibration of the Heston model developed so far and meets the speed requirement of practical trading.},
archivePrefix = {arXiv},
arxivId = {1511.08718},
author = {Cui, Yiran and {del Ba{\~{n}}o Rollin}, Sebastian and Germano, Guido},
doi = {10.1016/j.ejor.2017.05.018},
eprint = {1511.08718},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/cui17.pdf:pdf},
issn = {03772217},
journal = {European Journal of Operational Research},
keywords = {Heston model,Levenberg–Marquardt method,Model calibration,Optimisation,Pricing},
month = {dec},
number = {2},
pages = {625--638},
publisher = {Elsevier B.V.},
title = {{Full and fast calibration of the Heston stochastic volatility model}},
volume = {263},
year = {2017}
}
@article{chr02,
abstract = {Which loss function should be used when estimating and evaluating option valuation models? Many different functions have been suggested, but no standard has emerged. We emphasize that consistency in the choice of loss functions is crucial. First, for any given model, the loss function used in parameter estimation and model evaluation should be the same, otherwise suboptimal parameter estimates may be obtained. Second, when comparing models, the estimation loss function should be identical across models, otherwise inappropriate comparisons will be made. We illustrate the importance of these issues in an application of the so-called Practitioner Black-Scholes model to S{\&}P 500 index options. {\textcopyright} 2003 Elsevier B.V. All rights reserved.},
author = {Christoffersen, Peter and Jacobs, Kris},
doi = {10.1016/j.jfineco.2003.02.001},
file = {:D$\backslash$:/GoogleDrive/TFM/Bibliography sources/chr02.pdf:pdf},
issn = {0304405X},
journal = {Journal of Financial Economics},
keywords = {Implied volatility functions,Out-of-sample forecasting,Parameter stability,Valuation errors},
title = {{The importance of the loss function in option valuation}},
year = {2004}
}
